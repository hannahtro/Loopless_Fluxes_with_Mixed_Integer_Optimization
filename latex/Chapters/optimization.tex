\section{Mathematical Optimization} \label{section:optimization}
\todo[inline]{link to other sections}
Optimization appears in various disciplines. 
In timetabling, we seek a schedule at school such that teachers are assigned to students at a given time \cite{timetabling}. Of course different requirements have to be satisfied. Each teacher and student should have only on class at a time. The classes should not be too big and the teachers are only allowed to teach a limited number of hours per week. 
Another example for an optimization problem is clustering, where we want to divide a set of data points into subsets that share similarities \cite{clustering}. 
Optimization also arises in nature. Animals adapt and optimize their behaviour through learning \cite{optimization_systems_biology}. And even the behaviour in cells optimizes biological objectives such as maximizing growth or minimizing energy usage \cite{intro_computational_systems_biology}. Optimization in cells is the topic of this thesis and we will see in \cref{section:metabolic_networks} how to use mathematical optimization to answer questions arising in systems biology.

In mathematical optimization, the goal is to find an optimal solution that respects requirements that arise in our application. In order to represent a problem in practice by a mathematical model, we need to formulate an objective. An objective in timetabling could be minimizing the number of used classrooms, and in clustering an objective is to minimize the difference of points in the same cluster. Additionally, we need to identify entities of the system. In timetabling, we would have student, teachers, rooms and time as different entities in the model. We also need to identify constraints in our system. Once the objective, the entities and the requirements of a system are identified, it can be expressed mathematically.
The resulting model is an \textit{optimization problem}, and we can use optimization algorithms to compute solutions. 
We define an optimization problem as:
\begin{mini!}
    {\scriptstyle \bold x \in \mathbb{R}^n}{f(\bold x)}{ \label[problem]{problem:optimization_problem}}{}
    \addConstraint{g_i(\bold x) \leq 0, \quad i=1,...,m} 
\end{mini!}

\quad where $f$ is the \textit{objective function}, $g_i$ are the \textit{constraint functions} and $\bold x$ are the \textit{decision variables}. %\cite{boyd_stephen_convex_2004}
The \textit{feasible region} is the set of points that respect the constraints. An optimization problem with a constrained feasible region is often also called \textit{constrained optimization problem} in contrast to an \textit{unconstrained optimization problem}. A \textit{solution} is a vector $\bold x$ that lies in the feasible region. An \textit{optimal solution} $\bold x^*$ is a solution with the smallest objective value. The \textit{objective value} of $\bold x^*$ is the value of the objective function evaluated at $\bold x^*$. If a problem has no solution it is said to be \textit{infeasible}. A problem is \textit{unbounded} if solutions exist, but the objective value can be arbitrarily small.
One can maximize a function $f$ by setting the objective function to $\min -f(\bold x)$.
Depending on the type of the objective function and the type of constraints, optimization problems are divided into different classes. The classes relevant for this thesis are linear programs, mixed-integer programs and disjunctive programs\footnote[1]{Program here does not mean a computer program. The term was coined in the 1950s and referred to planning in a military context. See \cite{understanding_lp} for more detail.}. 
Different algorithms can be used to solve optimization problems, which depend on the problem structure.
% \todo[inline]{or define solution as optimal solution}

\subsection{Preliminaries and Notation}
\todo[inline]{use variables consistently; check when to use if and when iff; which words to write in italic \\ %all matrices bold and capitalized to differentiate btw matrix and vector? --> capitalized yes for matrices, bold is up to you.
}

\begin{enumerate}
    \item The set $\mathbb{R}$ denotes the set of real numbers and the set $\mathbb{Z}$ denotes the set of whole numbers. If scalar $\alpha$ is in the set of real numbers, we write $\alpha \in \mathbb R$. \todo[inline]{remove?} %(instead of $\mathbb R ^1$) 
    
    \item A vector $\bold{v} = (v_1, ..., v_n) \in \mathbb{R}^n$ is identified as a column vector and printed in bold. $\bold v^\intercal$ transposes $\bold v$ into a row vector. The inner product of two vectors $v, w \in \mathbb{R}^n$ is $\bold v^\intercal \bold w = \sum_{i=1}^n v_i w_i$. $\bold v \leq \bold w$ denotes element-wise inequality. $\ln (\bold v)$ denotes the element-wise natural logarithm. 
    The 1-vector is written as $\bold 1 := (1, 1, ..., 1) \in \mathbb{R}^n$ the 0-vector as $\bold 0 := (0, 0, ..., 0) \in \mathbb{R}^n$. The \textit{support} of $\bold{v}$ is the set of indices $i$ with $v_i \neq 0$ and is denoted by $\text{supp}(\bold v)$. $\text{sign}(\bold v)$ is the element-wise sign function applied.
    The concatenation of two vectors $\bold x$, $\bold y$ is denoted as $(\bold x, \bold y)$.

    \item The entry in row $i$ and column $j$ of a matrix $ \bold A \in \mathbb{R}^{n \times m}$ is denoted as $a_{i,j}$. The $i$-th row is $\bold a_{i,*}$ and the $j$-th column $\bold a_{*,j}$. \todo[inline]{update in entire section, often one index used for row of matrix} The zero matrix is denoted by $\bold 0_{m,n}$ with $m$ rows and $n$ columns. $\text{diag}(\bold v)$ is the quadratic matrix with $\bold v$ on the diagonal and 0 for all other entries.
    
    \item Let $\bold A \in \mathbb{R}^{n \times n}$ be an invertible matrix: $ \bold A \bold A^{-1} = \bold I$, where $\bold I$ is the identity matrix. The matrix $ \bold A^{-1}$ is the inverse matrix of $ \bold A$. %\todo[inline]{when is matrix invertible}
    $\bold I_n$ is the $n \times n$ idendity matrix.

    \item A \textit{linear combination} is defined as $\sum_{i=1}^{m} \lambda_i \bold x_i = 
    \lambda_i x_1 + ... + \lambda_m x_m$, where $\lambda_i \in \mathbb{R}$ and $x_i \in \mathbb{R}^n$.
    A line going through a point $\bold x$ generated by $\bold r \in \mathbb{R}^n$ is the set $\{\bold x + \lambda \bold r | \lambda \in \mathbb{R}\}$. A \textit{line segment} is a subset of a line defined on the interval between $l \in \mathbb{R}$ and $u \in \mathbb{R}$: $\{\bold x + \lambda \bold r | \lambda \in \mathbb{R}, \, \lambda \in [l, u ]\}$.

    \item A \textit{Basis} $B$ of a vector space $V$ is a set of vectors $(\bold v_1, \bold v_2, ..., \bold v_n)$ that are linearly independent and every $\bold v \in V$ can be written as a linear combination of vectors in $B$.

    \item The \textit{nullspace} of a matrix $\bold A \in \mathbb{R}^{n \times m}$ is defined as $\text{null}(\bold A):=\{\bold x \in \mathbb{R}^n: \bold A \bold x = \bold 0\}$. 
    
    \item A set $C \subseteq \mathbb{R}^n$ is \textit{convex} if for any two points $\bold x, \bold y \in C$ the line segment between them is in $C$. %every convex combination for any two points $x,y \in X$ is contained in $C$.
    The \textit{convex hull} of a set $X$ is the smallest convex set that contains all points in $X$ and denoted as $\text{conv}(X)$. It is a set of convex combinations such that all points $x_i$ in $X$ can be represented, where a \textit{convex combination} is a linear combination with $\lambda_i \geq 0$ and $\sum_{i=1}^m \lambda_i = 1$.
    
    \item The set $\{\bold x \in \mathbb{R}^n | \boldsymbol \alpha^\intercal \bold x = \boldsymbol \beta \}$ is a \textit{hyperplane}, where $\boldsymbol \alpha \in \mathbb{R}^n$ and $\boldsymbol \beta \in \mathbb{R}$. The set $\{\bold x \in \mathbb{R}^n | \boldsymbol \alpha^\intercal x \leq \boldsymbol \beta \}$ is a \textit{half-space}. \cite{understanding_lp}
    A \textit{polyhedron} is the intersection of a finite number of half-spaces: $P = \{ \bold x | \bold A \bold x \leq \bold b\}$. Hyperplanes, half-spaces and polyhedra are convex. A point $\bold x \in P$ is an \textit{extreme point} or \textit{vertex} if it cannot be represented as a convex combination of any other points in $P$. %\todo[inline]{closed halfspace needed?} 
    A polyhedron is also called \textit{polytope} if $P$ can be written as the convex hull of the extreme points of $P$. \todo[inline]{verify}
   
    \item A set $C \subseteq \mathbb{R}^n$ is a \textit{cone} if $\lambda \bold x \in C$ for any $\bold x \in C$ and $\lambda \geq 0$. A \textit{conic combination} is a linear combination with $\lambda \geq 0$. A cone is a \textit{convex cone} if it contains the conic combinations of all $x_i \in C$. $C$ is \textit{pointed} if it contains no line and the extreme point is called $apex$. A vector $\bold r \in \mathbb{R}^n$ is a \textit{ray} of $C$ iff $\{\bold x + \lambda \bold r | \lambda \geq 0 \} \in C$ for any $\bold x \in C$ and nonzero $\bold r$. Ray $r$ is an \textit{extreme ray} if it cannot be represented by a conic combination of other rays in $C$. 
    A cone is $polyhedral$ if the number of extreme rays is finite. A cone is \textit{simplicial} if it has $n$ extreme rays. \todo[inline]{verify}
    The \textit{conic relaxation} of an extreme point $\bold x$ of a polyhedron $P$ is a cone with apex $\bold x$ and where the extreme rays are the half-spaces of $P$ intersecting at $\bold x$.
    
    % \unsure[inline]{how to define ray, as r as lambda r or as x + lambda r}
    \item Let $S$ be a set and $\bold x$ a point in $S$. $\bold x$ is in the \textit{interior} of $S$, denoted as $\text{int}(S)$, if there exists an $\epsilon > 0$ such that any point in the ball centered at $\bold x$ with radius $\epsilon$ is contained in $S$. $\bold x$ is on the \textit{boundary} of $S$, denoted as $\text{bd}(S)$, if it is not in $\text{int}(S)$. $S$ is \textit{closed} if the boundary of $S$ is contained in $S$, $S$ is said to be \textit{open} otherwise. %https://wiki.math.ntnu.no/linearmethods/basicspaces/openandclosed
    % \todo[inline]{does ball have to be open? subset of euclidean space.\\MB: you can specify if you consider balls as closed or open by default. People use open ball and closed ball explicitly when it matters.}
    This also holds if the boundary is the empty set and therefore $\mathbb{Z}$ is closed.
\end{enumerate}

\subsection{Linear Programming} \label{section:Linear Programming}
A \textit{linear program} (LP) is an optimization problem with a linear objective function and linear constraints.

\begin{mini!}
    {\scriptstyle x}{\bold c^\intercal \bold x}{\text{\textbf{LP:}} \label[problem]{problem:LP}}{}
    \addConstraint{\bold A \bold x\leq \bold b} 
    \addConstraint{\bold x \in \mathbb{R}^n}
    % \addConstraint{x\geq \bold 0} 
\end{mini!}

\quad where $\bold c \in \mathbb{R}^n$, $ \bold A \in \mathbb{R}^{m \times n}$ and $\bold b \in \mathbb{R}^m$. It is assumed that the number of constraints $m$ is greater than the number of variables $n$. %\unsure[inline]{to have an \textit{underdetermined} system of linear equations which allows to have many solutions} \todo[inline]{there can be many solutions regardless: e.g. a half space -> many solutions (M.)} 
The linear inequalities define a polyhedron. If an optimal solution exists, there exists an optimal solution at one of the vertices. In that case, the LP can have exactly one optimal solution, or multiple optimal solutions if an entire edge or face is optimal. An LP has no optimal solution if it is infeasible or unbounded.
\cref{problem:LP} is said to be in \textit{inequality form}%\unsure[inline]{ok to do so without constraints on x?}
.

As an example, we want to solve the following optimization problem: 
\begin{maxi!}
    {\scriptstyle x, y}{y}{ \label[problem]{problem:lp_example}}{}
    \addConstraint{0 \leq x \leq 3} 
    \addConstraint{0.5 \leq y \leq 4} 
    \addConstraint{y \leq 1.5 x + 0.5} 
    \addConstraint{y \leq -0.5 x + 4.5}
    \addConstraint{x,y \in \mathbb{R}}
\end{maxi!}
% \begin{equation} \label[problem]{problem:lp_example}
%     \text{max} \{y \, : \, 0 \leq x \leq 3 , \, 0.5 \leq y \leq 4, \, y \leq 1.5 x + 0.5, \, y \leq -0.5 x + 4.5, \, x,y \in \mathbb{R} \}
% \end{equation} 
The decision variables $x, y$ are continuous. We want to find a solution $(x^*, y^*)$ with maximal $y$-value such that the constraints are respected. The problem is a linear program and can be written as \cref{problem:LP} by simple linear transformations. If we want to write \cref{problem:lp_example} as a minimization problem, the objective becomes $-y$. If we visualise the example (\cref{fig:lp}), we see that there exists one optimal solution located at $(2,3.5)$. Usually, we are interested in problems in higher dimensions and it is not possible to solve them visually.
% \todo[inline]{why orthogonal line to objective function has the same objective values}

\begin{figure}[h!]
    \caption{visualization of \cref{problem:lp_example}}
    \centering
    \includegraphics[width=0.6\textwidth]{Images/lp.pdf}
    \label{fig:lp}
    \subcaption*{
        The set of feasible solutions contains all the points in the interior or on the boundary of the polytope (blue line segments). The optimal solution $x^*$ is the point in the feasible region with the biggest $y$-value (red point). The isolines indicate the function value of the points.}
\end{figure} \unsure[inline]{remove grid?}

An LP is said to be in \textit{standard form} if it is of the form:
\begin{mini!}
    {\scriptstyle x}{\bold c^\intercal \bold x}{\label[problem]{problem:LP_standard_form}}{}
    \addConstraint{\bold A \bold x = \bold b} 
    \addConstraint{\bold x \geq \bold 0} 
\end{mini!}

\quad where $\bold c, \bold x \in \mathbb{R}^n, \, \bold A \in \mathbb{R}^{m \times n}$ and $\bold b \in \mathbb{R}^m$. 
\cref{problem:LP} can be written in standard form by adding one \textit{slack variable} per inequality to write it as equality \cite{noauthor_numerical_2006}. $\bold a_{i,*}^\intercal \bold x \leq b_i$ becomes $\bold a_{i,*} \,^\intercal \bold x + s_i = b_i$ with $s_i \geq 0$. Each variable $x_i$ that can be negative is replaced by $x_i^+ - x_i^-$, where $x_i^+ \geq 0$ and $x_i^- \geq 0$ \cite{noauthor_numerical_2006}.

A vertex of the feasible region is also called \textit{basic feasible solution}. Suppose we have an LP in polyhedral form as in \cref{problem:LP}. Let $\bold x \in \mathbb{R}^n$ be a basic feasible solution. There exist $n$ constraints that are a basis defining $\bold x$. $B$ is the set of constraint indices that are in the basis. Any variable $x_i \in B$ is a \textit{basic variable}. A variable $x_i \not \in B$ is a \textit{nonbasic variable} and $x_i=0$ \cite{understanding_lp}.

\subsubsection{Solving LPs}
There exist several algorithms to solve linear programs. The \textit{ellipsoid method} is the first algorithm that was proven to have a polynomial runtime in the worst case. However, in practice, other algorithms outperform it \cite{understanding_lp}. Another class of algorithms are \textit{interior-point methods}. Some interior-point methods have a polynomial runtime in the worst case and are often used in practice. Interior-point methods start with a feasible solution in the interior of the feasible region and approach the optimum without stepping outside of the feasible region \cite{understanding_lp}. 

Another algorithm that is relevant in practice is the \textit{simplex algorithm}. It is based on the fundamental property of LPs that the optimum is located at one of the vertices of the feasible region. %\todo[inline]{and that each vertex is corresponds to a basis, wrong words (M.)}. 
In \textit{phase \RomanNumeralCaps{1}} of the algorithm, a vertex of the feasible region is computed. In \textit{phase \RomanNumeralCaps{2}}, the algorithm moves from vertex to vertex along edges of the feasible region until an optimum is found. The \textit{pivot rule} determines to which vertex the algorithm moves next. There exist several pivot rules, however for all of them, there are families of problem instances on which the number of pivot steps needed grows exponentially. The worst case runtime on some instances is in conflict with the observed polynomial runtime in practice. Studying the simplex method with \textit{smoothed analysis}, which tries to close this gap, shows a polynomial runtime of the simplex method. In smoothed analysis, a small noise is added to the entries of a fixed instance and afterwards worst-case analysis is performed on the perturbed instance \cite{huiberts}, \cite{dadush}.
% \todo[inline]{when which algorithm is better}

\subsubsection{Optimality and Duality}
% \todo[inline]{transition}
To prove that a solution is optimal, we can use the KKT-conditions and see the relation between the primal and the dual problems in LPs. 
An optimization problem can be written as an unconstrained problem by augmenting the objective function with a weighted sum of the constraints \cite{boyd_stephen_convex_2004}. The resulting function is known as the \textit{Lagrangian}.
The Lagrangian of an LP in standard form is \cite{noauthor_numerical_2006}: 
\begin{equation} \label{Eq:lagrangian}
\mathcal{L} (\bold x, \boldsymbol{\lambda}, \boldsymbol \nu) = \bold c^\intercal \bold x - \sum_{i=1}^n \lambda_i x_i - \sum_{i=1}^m \bold \nu_i (A_{i,*}^\intercal \bold x - b_i)
\end{equation} %\todo[inline]{$\lambda_i (x_i)$ correct?}
where $\lambda_i \geq 0$ and $\nu_i \in \mathbb{R}$ are called \textit{Lagrange multipliers} or \textit{dual variables}.
As the objective function of linear programs is convex, the KKT-conditions are a proof for global optimality of a solution. We obtain the optimality conditions captured in \cref{theorem:lp_duality}. 

\begin{theorem}[Optimality conditions for LPs] \label{theorem:lp_duality}
    A solution $\bold x^*$ is optimal if there exist vectors $\boldsymbol \lambda$ and $\boldsymbol \nu$ that satisfy the following conditions \cite{noauthor_numerical_2006}:
    \begin{enumerate}
        \item $\boldsymbol \lambda + \bold A^\intercal \boldsymbol \nu = \bold c $ \hfill (stationarity)
        \item $ \bold A \bold x - \bold b = \bold 0$ \hfill (primal feasibility)
        \item $\bold x \geq \bold 0$ \hfill (primal feasibility)
        \item $\boldsymbol \lambda \geq \bold 0$ \hfill (dual feasibility)
        \item $\bold x^\intercal \boldsymbol \lambda = \bold 0$ \hfill (complementary slackness)
    \end{enumerate}
\end{theorem} 
We call a linear program in standard form as in \cref{problem:LP_standard_form} the \textit{primal problem} ($\mathcal{P}$).
The associated \textit{dual function} of the primal problem is \cite{aps_mosek_nodate}:
\todo[inline]{MB: shouldn't the conditions $x \geq 0, \lambda \geq 0$ appear somewhere?}
\begin{align*}
    q(\boldsymbol \lambda, \boldsymbol \nu)
    & = \min_{\bold x} \mathcal{L} (\bold x, \boldsymbol \lambda, \boldsymbol \nu) \\
    & = \min_{\bold x} \bold c^\intercal \bold x - \boldsymbol \lambda^\intercal \bold x - \boldsymbol \nu^\intercal (\bold A \bold x - \bold b) & \\
    & = \min_{\bold x} \bold c^\intercal \bold x - \boldsymbol \lambda^\intercal \bold x - \boldsymbol \nu^\intercal \bold A \bold x + \boldsymbol \nu^\intercal \bold b  &\\
    & = \min_{\bold x} (\bold c^\intercal - \boldsymbol \lambda^\intercal - \boldsymbol \nu^\intercal \bold A) \bold x + \boldsymbol \nu^\intercal \bold b  &\\
    & = \min_{\bold x} \bold x^\intercal (\bold c - \boldsymbol \lambda - \bold A^\intercal \boldsymbol \nu) + \bold b^\intercal \boldsymbol \nu &\\
    & = %\left\{
    \begin{array}{lr}
        \bold b^\intercal \boldsymbol \nu \quad \quad \text{if} \, \, \bold c - \boldsymbol \lambda - \bold A^\intercal \boldsymbol \nu = \bold 0\\
        - \infty \quad \quad \text{otherwise}
    \end{array}
\end{align*}
Let $\bold x^P$ be a feasible solution to the primal problem, and let $(\boldsymbol \lambda^D, \, \boldsymbol \nu^D)$ be a feasible solution to the dual problem. If the dual function is bounded we know that $\bold c - \boldsymbol \lambda^D = \bold A^\intercal \boldsymbol \nu^D$ and we know that $\bold x^P$ satisfies $ \bold A\bold x^P = \bold b$. The function value $q(\boldsymbol \lambda^D, \boldsymbol \nu^D)$ is a lower bound on the objective value of the primal problem \cite{aps_mosek_nodate}: 
\begin{equation*}
    \bold b^\intercal \boldsymbol \nu^D
    = (\bold A \bold x^P)^\intercal \boldsymbol \nu^D 
    = \bold {x^P}^\intercal \bold A^\intercal \boldsymbol \nu^D 
    = \bold {x^P}^\intercal (\bold c - \boldsymbol \lambda^D) 
    = \bold c^\intercal \bold x^P  - \boldsymbol {\lambda^D}^\intercal \bold x^P
    \leq \bold c^\intercal \bold x^P
\end{equation*}
The tightest bound maximizes $\bold b^\intercal \boldsymbol \nu$. Formulated as a linear program we obtain the \textit{dual problem} ($\mathcal{D}$):
\begin{maxi!}
    {\scriptstyle \boldsymbol \nu, \boldsymbol \lambda}{\bold b^\intercal \boldsymbol \nu}{\label[problem]{problem:dual_problem_slack}}{}
    \addConstraint{\boldsymbol \lambda + \bold A^\intercal \boldsymbol \nu = \bold c} 
    \addConstraint{\boldsymbol \lambda \geq \bold 0} 
\end{maxi!}
or rewritten without the slack variables $\boldsymbol \lambda$ \cite{noauthor_numerical_2006}:
\begin{maxi!}
    {\scriptstyle \boldsymbol \nu}{\bold b^\intercal \boldsymbol \nu}{\label[problem]{problem:dual_problem}}{}
    \addConstraint{\boldsymbol A^\intercal \boldsymbol \nu \leq \bold c} 
\end{maxi!}
% \unsure[inline]{add dimensions to all variables}
Let $p^*$ be the objective value of an optimal solution for the primal problem and $d^*$ the objective value of an optimal solution to the dual problem. We have seen that $d^*$ is a lower bound on $p^*$ which is known as \textit{weak duality}. 
\begin{theorem}[Strong Duality] \label{theorem:strong_duality}
    Given a primal $\mathcal{P}$ and corresponding dual program $\mathcal{D}$, exactly one of the following is true \cite{noauthor_numerical_2006}:
    \begin{enumerate}
        \item $\mathcal{P}$ and $\mathcal{D}$ both have at least one optimal solution. If $p^*$ is the objective value of an optimal solution to $\mathcal{P}$ and $d^*$ is the objective value of an optimal solution to $\mathcal{D}$, then $p^*=d^*$.
        \item Either $\mathcal{P}$ or $\mathcal{D}$ is unbounded and the other is infeasible. 
        \item $\mathcal{P}$ and $\mathcal{D}$ both are infeasible.
    \end{enumerate}
\end{theorem}
For linear programs, \textit{strong duality} holds. A proof for \cref{theorem:strong_duality} can be found in \cite{aps_mosek_nodate}. Property (1) of \cref{theorem:strong_duality} can be used to prove the optimality of a solution. 

We have seen how to derive the dual problem of an LP in standard form. We do not require an LP in standard form to derive the corresponding dual problem. For example, the dual problem of \cref{problem:LP} is: 
\begin{maxi!}
    {\scriptstyle x}{\bold b^\intercal \boldsymbol{\mu}}{\label[problem]{problem:LP_dual}}{}
    \addConstraint{\bold A^\intercal \boldsymbol{\mu} = \bold c} 
    \addConstraint{\mu_i \geq 0}
    % \addConstraint{x\geq \bold 0} 
\end{maxi!}

% \todo[inline]{example + visualization}
% \begin{lemma}[Farkas Lemma]
%     Given an LP in standard form, exactly one of the following is true:
%     \begin{enumerate}
%         \item the LP has at least one solution $x$
%         \item there exists a vector $y$ such that $ \bold A^\intercal y \leq 0$ and $b^\intercal y > 0$
%     \end{enumerate}
% \end{lemma}

% \cite{aps_mosek_nodate}

\subsection{Mixed-Integer Programming} \label{section:MIP}
Many problems in practice cannot be formulated by only using linear constraints and continuous decision variables. It is often required that a subset of variables is discrete. A \textit{mixed-integer program} (MIP) is an optimization problem with a linear objective function, linear constraints and a subset of integer variables:

\begin{mini!}
    {\scriptstyle \bold x}{\bold c^\intercal \bold x}{\text{\textbf{MIP:}} \label[problem]{problem:MIP}}{}
    \addConstraint{\bold A \bold x\leq \bold b} \label[constraint]{constraint:MIP_inequality}
    % \addConstraint{x\geq \bold 0} 
    \addConstraint{\bold x \in \mathbb{Z}^{|J|} \times \mathbb{R}^{n-|J|} \label[constraint]{constraint:MIP_integer}
    }
\end{mini!}

\quad where $\bold c \in \mathbb{R}^n, \, \bold A \in \mathbb{R}^{m \times n}$, $\bold b \in \mathbb{R}^m$. The set $J$ contains the indices of integer variables. 

Let us reuse the LP example in \cref{section:Linear Programming} and add integrality constraints on the decision variables $x$ and $y$:
\begin{maxi!}
    {\scriptstyle x, y}{y}{ \label[problem]{problem:mip_example}}{}
    \addConstraint{0 \leq x \leq 3} 
    \addConstraint{0.5 \leq y \leq 4} 
    \addConstraint{y \leq 1.5 x + 0.5} 
    \addConstraint{y \leq -0.5 x + 4.5}
    \addConstraint{x,y \in \mathbb{Z}}
\end{maxi!}
% \begin{equation} \label[problem]{problem:mip_example}
%     \text{max} \{y \, : \, 0 \leq x \leq 3 , \, 0.5 \leq y \leq 4, \, y \leq 1.5 x + 0.5, \, y \leq -0.5 x + 4.5, \, x,y \in \mathbb{Z} \}
% \end{equation} 

Looking at the visualisation of the problem (\cref{fig:mip}), we see that the optimal solution of the LP $x^{LP} = (2,3.5)$ is no valid solution for the MIP formulation. The points $(2,3)$ and $(3,3)$ are the optimal solutions.

\begin{figure}[h!]
    \caption{visualisation of \cref{problem:mip_example}}
    \centering
    \includegraphics[width=0.6\textwidth]{Images/mip.pdf}
    \label{fig:mip}
    \subcaption*{
        The feasible points of the MIP are the integer points respecting the polyhedral constraints (blue points). The set of feasible solutions to the relaxed LP is are all the points in the interior or on the boundary of the polytope (blue line segments). An optimal solution is a point in the feasible region with the biggest $y$-value (red point). The optimal solutions are at $(2,3)$ and $(3,3)$.}
\end{figure}

The MIP formulation enables us to model much more complex problems. Apart from incorporating discrete quantities, it is possible to capture Boolean expressions. Suppose we want to model the \textit{indicator constraint} $z = 1 \implies \bold a^\intercal \bold x \leq b$. We can reformulate the constraint with a linear constraint using the \textit{big-M method}: 
\begin{equation*}
    \bold a^\intercal \bold x \leq b + M(1-z)
\end{equation*}
If $z=1$ the constraint is enforced. In the case $z=0$, the value of $M$ has to be larger than $\bold a^\intercal \bold x - b$ for any $\bold x$ such that the constraint is inactive \cite{aps_mosek_nodate}.

\subsubsection*{Solving MIPs} \addcontentsline{toc}{subsubsection}{\protect\numberline{}Solving MIPs}
Solving MIPs is much more complicated than solving LPs, because it is not guaranteed that if an optimal solution exists, it is at one of the vertices. In general, solving MIPs is $\mathcal{NP}$-hard. A problem is $\mathcal{NP}$-hard if it requires at least as much time to solve the problem as any other problem that is $\mathcal{NP}$-complete. $\mathcal{NP}$-complete problems are $\mathcal{NP}$-hard and a solution is verifiable in polynomial time. In complexity theory, problems are defined as decision problems.\cite{CormenIntroduction} 
The decision problem of \cref{problem:MIP} would be "Is the feasible region nonempty?", which is $\mathcal{NP}$-complete. As finding an optimal solution is not easier than finding any solution, it follows that MIPs are $\mathcal{NP}$-hard. \cite{integer_programming}
% NP: set of decision problems solvable in polynomial time and verifiable in polynomial time 
% NP-hard: polynomial time reduction from an NP-complete problem G to H -> H can be optimizatoin problem
% 0-1 integer linear programmings is NP-complete
% MILP feasibility problem is in NP:
% - yes verifiable in polynomial time
% - 

Instead of solving the MIP directly, one can solve a sequence of \textit{LP relaxations}: the integrality constraints are ignored and \cref{constraint:MIP_integer} becomes $\bold x \in \mathbb{R}^n$.
Let $z^{LP}$ be the objective value of an optimal solution $\bold{x}^{LP}$ of the LP relaxation and $z^*$ the objective value of an optimal solution $\bold{x^*}$ to the MIP problem. We know that: 
\begin{equation*} \label{Eq:bound}
    z^{LP} \leq z^*
\end{equation*}
One common approach for solving MIPs is the \textit{branch-and-bound} algorithm \cite{integer_programming}. The idea is to generate a branch-and-bound tree starting with the solution to the LP relaxation $\bold x^{LP} \in \mathbb{R}^n$ at the root node. A variable $x_i$ that is fractional in $\bold x^{LP}$ and violates the integrality constraint is selected as \textit{branching variable}. We divide the search space $P$ by creating two child nodes. In one $x_i$ has to be larger or equal to the rounded up value and the feasible region becomes $P \cap \{x_i \geq \lceil x_i^{LP} \rceil \}$. In the other child node, $x_i$ can take at most the rounded down value of $x_i^{LP}$ and the feasible region of the subproblem is $P \cap \{x_i \leq \lfloor x_i^{LP} \rfloor \}$. The solution with the smallest objective value respecting the MIP formulation is called \textit{incumbent} and the objective value is denoted by $z^{INC}$. We continue branching until all variables in $J$ are integral, a subproblem is infeasible or if a node can be $pruned$. The optimal solution in each node $i$ is bounded by the objective value of the relaxed solution $z^{LP}_{(i)}$. If $z^{LP}_{(i)}$ is greater or equal to $z^{INC}$, node $i$ is cut off the tree. 

% \todo[inline]{add figure for branching}

Another approach to solve MIPs is the \textit{cutting plane} algorithm \cite{integer_programming}. The LP relaxation can be very weak. As we are dealing with a linear objective, we could get the optimal MIP solution easily if we had access to the \textit{integer hull}: $\text{conv}(P \cap \mathbb{Z}^n)$. If the LP relaxation does not correspond to the integer hull, one can tighten the LP relaxation by adding \textit{cuts}. A cut is an inequality that does not cut off any feasible solution (see \cref{section:cuts}). Given an optimal solution to the LP relaxation $\bold x^{LP}$ that violates at least one integer constraint, one separates $\bold x^{LP}$ from the hull with a cut. This process is repeated until $\bold x^{LP}$ is an optimal solution to the MIP.

A combination of the branch-and-bound algorithm and the cutting plane algorithm is the \textit{branch-and-cut} algorithm \cite{integer_programming}. The LP relaxation at a node is potentially tightened by adding cuts. 

\subsection{Disjunctive Programming}
% \todo[inline]{motivation from MIP to DP}
Often, the requirements of a problem are complex, and linear constraints are not sufficient for the mathematical program. With Boolean expressions, more complicated relationships between variables can be captured without using the big-M formulation.     
A \textit{disjunctive program} (DP) is an optimization problem with linear constraints, continuous variables and logical constraints:

\begin{mini!}
    {\scriptstyle \bold x}{\bold c^\intercal \bold x}{\text{\textbf{DP:}} \label[problem]{problem:DP}}{}
    \addConstraint{\bold A \bold x\leq \bold b} 
    \addConstraint{\bigvee_{i \in Q_j} \{\bold d^{(i)\intercal} \bold x \leq d_{0}^i\} \quad \forall j \in S} 
\end{mini!}

\quad where $\bold c, \bold x \in \mathbb{R}^n$, $ \bold A \in \mathbb{R}^{m \times n}$ and $\bold b \in \mathbb{R}^m$. $\bold d^{(i)} \in \mathbb{R}^n, \, d_{0}^i \in \mathbb{R}$ and $S$ is the set of disjunction indices.
As the terms $i$ in each disjunction $Q_j$ are linear, each disjunctive set is a polyhedron. The feasible region is in general non-convex due to the disjunctive constraints \cite{balas_disjunctive_2018}.
Alternatively, the disjunctions can be captured by Boolean variables $Y_{ij} \in \{true, false \}$, where $Y_{ij}$ corresponds to the $i$-th disjunct in disjunction $j$:
\begin{mini!}
    {\scriptstyle \bold x}{\bold c^\intercal \bold x}{\label[problem]{problem:DP_bool}}{}
    \addConstraint{\bold A \bold x\leq \bold b} 
    \addConstraint{\bigvee_{i \in Q_j} \left[ \begin{array}{c}  
        Y_{ij}\\ 
        \{\bold d^{(i)\intercal} \bold x \leq d_{0}^i\}
    \end{array} \right] \quad \forall j \in S} 
    \addConstraint{\Omega (Y) = true}
\end{mini!}

As an example, we want to solve the following optimization problem:
% \begin{align} 
%     \begin{split}
%     \text{max} \{y \, : \, &((0 \leq x \leq 1) \land (0.5 \leq y \leq 1.5 x + 0.5)) \, \lor \\ &((2 \leq x \leq 3) \land (0.5 \leq y \leq -0.5 x + 4.5))  \, x,y \in \mathbb{R} \}
%     \end{split}
% \end{align} 
\begin{maxi!}
    {\scriptstyle x, y}{y}{\label[problem]{problem:dp_example}}{}
    \addConstraint{\begin{aligned}((0 \leq x \leq 1) \land (0.5 \leq y \leq 1.5 x + 0.5)) \, \, \lor \\ ((2 \leq x \leq 3) \land (0.5 \leq y \leq -0.5 x + 4.5)) \end{aligned}} 
    \addConstraint{x,y \in \mathbb{R}} 
\end{maxi!}

The feasible region is the union of two polyhedra and no longer convex. The optimal solution is the point with maximal value in either of the polytopes and located at $(2, 3.5)$ which we see in the visualization (\cref{fig:dp}). 

\begin{figure}[h!]
    \caption{visualization of \cref{problem:dp_example}}
    \centering
    \includegraphics[width=0.6\textwidth]{Images/dp.pdf}
    \label{fig:dp}
    \subcaption*{
        The set of feasible solutions is no longer convex and is the union of the polytope $P_1$ (blue line segments) and the polytope $P_2$ (orange line segments). The optimal solution $x^*$ is the point in the feasible region with the biggest $y$-value (red point).}
\end{figure}
% \unsure[inline]{write problem in dp form?}

\subsubsection*{Solving DPs} \addcontentsline{toc}{subsubsection}{\protect\numberline{}Solving DPs} \label{section:solving_dps}
A disjunctive model can be formulated as mixed-integer program and solved by corresponding techniques (see \cref{section:MIP}). Disjunctions can be expressed by linear constraints and integer variables by using the big-M method. Suppose we have a disjunction with $k$ terms:
\begin{equation*}
    (\bold a_1^\intercal \bold x \leq b_1) \lor (\bold a_2^\intercal \bold x \leq b_2) ... \lor (\bold a_k^\intercal \bold x \leq b_k)
\end{equation*}
We use the binary variable $y_i$ and enforce with the constraint $y_1 +  y_2 + ... + y_k \geq 1$ that at least one of the $k$ terms is true. If $y_i=1$, term $(\bold a_i^\intercal \bold x \leq b_i)$ is enforced. See \cref{section:MIP} on how to express indicator constraints with linear constraints and binary variables. Often, the $M$ constant has to be large to be inactive if $y_i=0$. However, a large $M$ leads to a weaker LP relaxation which impacts the runtime of the Branch-and-Bound algorithm \cite{aps_mosek_nodate}. 

Another possibility is to convexify the feasible region and solve the resulting linear program. The idea is to build the convex hull of the union of polyhedral points in a higher dimension. The optimal solution at a vertex of the convex hull is optimal for the disjunctive program, as we are dealing with linear constraints. % and project the solution back to the original dimension of the problem. 
For an example on how to write a disjunctive program using the big-M or the hull reformulation, we refer to \cite{perez_disjunctiveprogrammingjl_2023}.
\cref{fig:dp_solving_techniques} shows the 2D-projection of the big-M reformulation and the convex hull reformulation of a disjunctive program. 

\unsure[inline]{how to solve if corner can be infeasible?}
\todo[inline]{update example and create own figure for hull and big M diagram}
\begin{figure}[h!]
    \caption{taken from \cite{hutchison_automating_2010}}
    \centering
    \includegraphics[width=1.0\textwidth]{Images/dp_solving_techniques.png}
    \label{fig:dp_solving_techniques}
    \subcaption*{The feasible region of a disjunctive program (left), the approximation of the region using the big-M reformulation (center) and the convex-hull reformulation (right).}
\end{figure}

\subsection{Cutting Planes} \label{section:cuts}
Let us consider a mixed-integer problem (\cref{problem:MIP}) with decision variables $\bold x$. A \textit{cutting plane} or \textit{cut}, parameterised by $\boldsymbol \alpha \in \mathbb{R}^{n+1}$, is an inequality that when added to the MIP does not remove any feasible solution, and is defined as: 
\begin{equation} \label{Eq:cuts}
    \sum_{i=1}^n \alpha_i x_i \leq \alpha_0 \quad  \forall \bold x \in P \cap S
\end{equation} 
\quad where $\alpha_i \in \mathbb{R}$, $P$ is the polyhedron defined by the inequality in \cref{constraint:MIP_inequality}, and $S$ is the set points satisfying \cref{constraint:MIP_integer}. Usually, cutting planes are used to cut off solutions to the relaxed problem that are infeasible in the original problem. 

\cref{fig:cuts} shows a visualisation of \cref{problem:mip_example} in which the optimal solution to the relaxed problem $\bold x^{LP}$ is not feasible in the MIP. $\bold x^{LP}$ is separated from the integer hull by cuts.

\begin{figure}[!h]
    \caption{Tightening the relaxed problem of \cref{problem:mip_example} with cuts}
    \centering
    \includegraphics[width=0.6\textwidth]{Images/mip_cut.pdf}
    \label{fig:cuts}
    \subcaption*{The feasible points of \cref{problem:mip_example} are the integer points within the polytope. In the relaxed problem, the integrality constraints are ignored. The optimal solution to the relaxed problem is $\bold x^{LP}=(2, 3.5)$. As $\bold x^{LP}$ is not an integer solution, it is cut off by adding cuts. The tightest cut is indicated by the red dashed line.}
\end{figure}
% \unsure[inline]{update caption, the relaxed problem is fix}

For a solution to the relaxed problem $\bold x^{LP}$ with $\bold x^{LP} \notin P \cap S$, there exist multiple hyperplanes separating $\bold x^{LP}$ from the actual feasible region. %\todo[inline]{MB: if you think of it, can there exists conditions where a unique hyperplane would separate a point from a convex set?}
As we want to tighten the search space, we are interested in cuts that cut off many infeasible points at once. There are different scores to estimate the quality of a cut \cite{turner_adaptive_2023}
. One scoring measure is \textit{efficacy} which is the signed distance from $\bold x^{LP}$ to the cutting plane:
\begin{equation}
    \text{eff}(\boldsymbol \alpha, \bold x^{LP}) := \frac{\boldsymbol \alpha^\intercal \bold x^{LP} - \alpha_0}{\lVert \boldsymbol \alpha \rVert}
\end{equation}

However, there is a tradeoff between the quality of a cut and the complexity of generating it.
\todo[inline]{numerical issues}
The cuts relevant for this thesis are explained in detail below. 

\subsubsection{No-Good Cuts}
Given an integer problem P as in \cref{problem:MIP} with only binary variables: $J=n$ and $x_i \in \{0,1\}$. Let $\bold x^{IP}$ a solution to the relaxed integer program,  where \cref{constraint:MIP_inequality} is relaxed. 
If $\bold x^{IP}$ is not a feasible solution to P, we want to exclude the solution from the search space. The following \textit{no-good cut} is added to the relaxed IP and forbids the assignment of integer variables in $\bold x^{IP}$:
\begin{equation*}
    \sum_{j \in J: x_j^{IP}=0} (1 - x_{j}) + \sum_{j \in J: x_j^{IP}=1} x_j \quad \leq \quad |J| -1
\end{equation*}
Such a cut usually tightens the feasible region of P marginally and it would require a large number of no-good cuts to arrive at the integer hull.

\subsubsection{Combinatorial Benders' Cuts} \label{section:optimization_CB}
Instead of forbidding one assignment of variables as with a no-good cut, with combinatorial Benders' cuts we generate stronger cuts, by identifying the subset of variables that lead to the infeasiblity. This section is based on \cite{codato_combinatorial_2006}.

Given a problem of the form:
\begin{mini!}
    {\scriptstyle \bold x, \bold z}{\bold c^\intercal \bold x}{\label[problem]{problem:mathematical_program_CB}}{} 
    \addConstraint{\bold F \bold x \leq \bold g}
    \addConstraint{\bold D \bold z \leq \bold e}
    \addConstraint{x_j = 1 \implies \bold a_{i,*}^\intercal \bold z \leq b_i \quad \forall i \in I}
    \addConstraint{x_j \in \{ 0,1 \}}
    \addConstraint{z_i \in \mathbb{R}}
\end{mini!} 
As the objective does not depend on $\bold z$ and as the decision variables $\bold x, \bold z$ are independent apart from the indicator constraints, we can split the problem into a \textit{master problem} (MP) and a \textit{subproblem} (SP). Constraint \cref{problem:mathematical_program_CB} (d) can be reformulated using the big-M method: $\bold A \bold z \leq \bold b + M(\bold 1- \bold x)$.

\begin{mini!}
    {\scriptstyle \bold x}{\bold c^\intercal \bold x}{\text{\textbf{MP:}} \label[problem]{problem:MP}}{}
    \addConstraint{\bold F \bold x \leq \bold g}    
    \addConstraint{\bold x \in \mathbb{R}^n}
    \addConstraint{x_j \in \{ 0,1 \}}
\end{mini!}
The master problem ignores the constraints on $\bold z$. The subproblem depends on a solution $\bold x^{MP}$ to the master problem. 

\begin{mini!}
    {\scriptstyle \bold z}{0}{\text{\textbf{SP:}} \label[problem]{problem:SP}}{}
    \addConstraint{\bold D \bold z \leq \bold e}
    \addConstraint{\bold a_{i,*}^\intercal \bold z \leq b_i + M(1- x_{j}^{MP}) \quad \forall i \in I}
\end{mini!}
% \unsure[inline]{write M as matrix, vector or constant}
If solution $\bold x^{MP}$ leads to a feasible subproblem, $\bold x^{MP}$ is an optimal solution to \cref{problem:mathematical_program_CB}. If the problem is infeasible, $\bold x^{MP}$ is not a feasible solution for the original problem. In that case we want to add a cut that removes $\bold x^{MP}$ from the search space. Suppose we have access to a \textit{minimal infeasible subsystem} (MIS) $C$ that is an inclusion-wise minimal set of row indices corresponding to the constraints in the subproblem that lead to infeasibility.
The subproblem can then be written as:
\unsure[inline]{define properly (M.)}
\begin{mini!}
    {\scriptstyle \bold z}{0}{}{}
    \addConstraint{\bold D \bold z \leq \bold e}
    \addConstraint{\bold a_{i,*}^\intercal \bold z \leq b_i + M_i(1- x_{j}^{MP}) \quad \forall i \in C}
\end{mini!}
% \todo[inline]{MB: do you even need big M constraints in the expression? The point of CB is precisely to avoid big M \\-> taken from \cite{codato_combinatorial_2006}}
The \textit{combinatorial Benders' cut} is then: 
\begin{equation*}
    \sum_{j \in C: x_j^{MP}=0} (1 - x_{j}) + \sum_{j \in C: x_j^{MP}=1} x_j \quad \leq \quad |C| -1
\end{equation*}

A minimal infeasible subsystem can be found by studying the dual problem of the infeasible subproblem. As the subproblem is a linear problem, strong duality holds and an infeasible primal problem implies an unbounded dual problem (see \cref{section:Linear Programming}).
To derive the dual problem of \cref{problem:SP} we write constraints (b) and (c) as one constraint and stack the variables in the vector $\bold y$: $\bold{\tilde A} \bold y \leq \bold{\tilde b}$. The dual is then:
\begin{maxi!}
    {\scriptstyle \boldsymbol \lambda}{\bold{\tilde b}^\intercal \boldsymbol \lambda}{\label[problem]{problem:primal_cb}}{}
    \addConstraint{\bold{\tilde A}^\intercal \boldsymbol \lambda = \bold 0}
    \addConstraint{\boldsymbol \lambda \geq \bold 0}
\end{maxi!}

As $\boldsymbol \lambda$ is a feasible solution the dual problem, the dual problem is unbounded, and there exist multiple feasible solutions. We are interested in a feasible solution with $\boldsymbol \lambda \neq \bold 0$ and therefore add the constraint $\bold{\tilde b}^\intercal \boldsymbol \lambda = \bold 1$. Now that the objective function is hidden in the constraints, we can set a different objective function.
The linear program to find minimal infeasible subsystems is then:
\begin{maxi!}
    {\scriptstyle \boldsymbol \lambda}{\sum_i w_i \lambda_i}{\label[problem]{problem:mis_lp}}{} 
    \addConstraint{\bold{\tilde A}^\intercal \boldsymbol \lambda = \bold 0}
    \addConstraint{\boldsymbol \lambda \geq \bold 0}
    \addConstraint{\bold{\tilde b}^\intercal \boldsymbol \lambda = \bold 1}
\end{maxi!}
\quad where $w_i$ is the weight corresponding to the dual variable $\lambda_i$. The support of each solution at a vertex of the feasible region of \cref{problem:mis_lp}  defines a minimal infeasible subsystem. By changing the weights in the objective, several MISs can be obtained for one infeasible MP solution. 


\subsubsection{Intersection Cuts} \label{section:optimization_intersection_cuts}

Suppose we are given a problem of the form:
\begin{mini}
    {\scriptstyle \bold x}{\bold c^\intercal \bold x}{}{} \label[problem]{problem:mathematical_program_S_P}
    \addConstraint{\bold x \in S \cap P}
\end{mini} 
\quad where $\bold c \in \mathbb{R}^n$, $P$ is a polyhedron, and $S \subset \mathbb{R}^n$ is a closed, potentially non-convex set.
In the LP relaxation of \cref{problem:mathematical_program_S_P}, the constraint set becomes $\bold x \in P$. However, the relaxation might not be a good approximation of the true feasible region. The polyhedral approximation 
can be tightened by adding intersection cuts \cite{bienstock_outer_product_free_sets}. 

% \todo[inline]{should be closed otherwise optimum not bounded}
% Instead of solving an optimization problem directly, a relaxed version of the problem is solved. For instance, instead of solving an ILP, one would solve the LP without integrality constraints. 

Let $\bold{\tilde x}$ be an optimal solution to the LP relaxation that is infeasible in the original problem: $\bold{\tilde x} \notin S$. %To derive an intersection cut, the intersection between the conic relaxation around $\tilde x$ and an $S$-free set $C$ containing $\tilde x$ is required. \cite{musalem_intersection_cuts}
The \textit{conic relaxation} at vertex $\bold{\tilde x}$ is a cone with apex $\bold{\tilde x}$ and the neighbouring edges are the extreme rays. For a given set $S$, the convex set $C$ is \textit{$S$-free} if: $S \cap \text{int}(C) = \emptyset$ \cite{bienstock_outer_product_free_sets}. 
\todo[inline]{ensure that method section is correct}  
The hyperplane intersecting the boundary of $C$ and the conic relaxation is the \textit{intersection cut} and when added to the problem will cut off $\bold{\tilde x}$. Due to convexity of the feasible region and given that the cutoff area lies in $C$, all feasible solutions remain in the resulting polyhedron %\todo[inline]{not necessarily polytope}. 
\cite{musalem_intersection_cuts}.
In order to generate deep cuts, the $S$-free set should be maximal. An $S$-free set $C$ is \textit{maximal} if $C \not \subset C'$ for any $S$-free set $C'$ \cite{bienstock_outer_product_free_sets}.

As an example, we derive an intersection cut for \cref{problem:mip_example}. A visualisation is shown in \cref{fig:intersection_cut}. 
% \begin{maxi!}
%     {\scriptstyle x, y}{y}{ \label[problem]{problem:intersection_cut_example}}{}
%     \addConstraint{0 \leq x \leq 3} 
%     \addConstraint{0.5 \leq y \leq 4} 
%     \addConstraint{y \leq 1.5 x + 0.5} 
%     \addConstraint{y \leq -0.5 x + 4.5}
%     \addConstraint{x,y \in \mathbb{R}}
% \end{maxi!}
% \begin{equation} \label[problem]{problem:intersection_cut_example}
%     \text{max} \{y \, : \, 0 \leq x \leq 3 , \, 0.5 \leq y \leq 4, \, y \leq 1.5 x + 0.5, \, y \leq -0.5 x + 4.5, \, x,y \in \mathbb{Z} \}
% \end{equation}
%The problem is a mixed-integer program as it has a linear objective, linear constraints and integrality constraints on the decision variables $x,y$. 
The optimal solution of the relaxed linear program to \cref{problem:mip_example} is $\boldsymbol{\tilde x} = (2, 3.5)$. The set $S$ contains all integer points: $S = \mathbb{Z}$. A possible $S$-free set $C$ is a disk where the center is $\boldsymbol{\tilde x}$ and the radius the distance between $\boldsymbol{\tilde x}$ and the closest integer, in our case $0.5$. 
%\todo[inline]{online if ray normalized}. 
The conic relaxation is the cone with apex $\boldsymbol{\tilde x}$ and the rays correspond to the active constraints at $\boldsymbol{\tilde x}$: $y \leq 1.5x + 0.5$ and $y \leq -0.5 x + 4.5$. 
%\todo[inline]{verify correctness, ACTIVE CONSTRAINTS != EXTREME RAYS (n-D), x + lambda r} 
% \unsure[inline]{okay to write like this in 2D?}
The intersection between the circle $C$ and the conic relaxation are the points $P_1 \approx (1.7,3.1)$ and $P_2 \approx (2.5,3.3)$. The area between $\boldsymbol{\tilde x}$ and the line going through $P_1$ and $P_2$ is cutoff by adding a constraint to the relaxed LP of \cref{problem:mip_example}. \unsure[inline]{differentiate point from vector in notation?}

\begin{figure}[H]
    \caption{diagram of intersection cut for \cref{problem:mip_example}}
    \centering
    \includegraphics[width=0.6\textwidth]{Images/intersection_cut.pdf}
    \label{fig:intersection_cut}
    \subcaption*{
        The feasible points of the MIP are the integer points respecting the polyhedral constraints (blue points). The set of feasible solutions to the relaxed LP is are all the points in the interior or on the boundary of the polytope (blue line segments). The optimal solution $\bold{ \tilde x}$ to the relaxed LP is the point in the feasible region with the biggest $y$-value (red point). A possible $S$-free set $C$ is a disk with center $\bold{\tilde x}$ and the radius being the distance between $\bold{\tilde x}$ and the closest integer (red circle). The conic relaxation are the extreme rays generated by $\bold{\tilde x}$ which correspond to the two active constraints at $\bold{\tilde x}$ (is indicated by the dotted, red line). The intersection of the conic relaxation and $C$ are the two points in green. The intersection cut is constructed with the line going through the intersecting points (dashed line in green). The area above the green line will be cut off and $\bold{\tilde x}$ is no longer a feasible solution.}
\end{figure} 

The conic relaxation at $\tilde x$ is a pointed cone with extreme point $\tilde x$ and can be written as: 
\begin{equation} \label{Eq:conic_relaxation}
    P' = \{ \bold{\tilde x} + \sum_{j=1}^n \lambda_j \bold r^j : \boldsymbol \lambda \geq 0 \}
\end{equation}
or as:
\begin{equation} \label{Eq:conic_relaxation_polyhedral}
    P' = \{\bold x|\bold{\tilde Ax} \leq \bold{\tilde b}\}
\end{equation} 
%\unsure[inline]{confusing to have two x?}
where $r^j$ are the extreme rays, $\bold{\tilde A}$ is an invertible $n\times n$ submatrix of $ \bold A$ such that the rows are linearly independent and are a basis for $\bold{\tilde x}$ \cite{bienstock_outer_product_free_sets}. 
% If the original problem is brought in the form $ \bold Ax \leq b$, the bounds on $x$ are included in $ \bold A$ and therefore $m \geq n$. 
A basis for $\bold{\tilde x}$ are the nonbasic constraints at $\bold{\tilde x}$.
If a constraint is nonbasic, the corresponding slack variable of the standard form is nonbasic and therefore 0. This implies that the constraint is active. 

Going back to \cref{problem:mip_example}, the polyhedral presentation of the conic relaxation at $(2, 3.5)$ is:
\begin{equation*}
    P' =     
    \left\{ (x,y) \Bigg|
        \left[ \begin{array}{cc}
            -1.5 & 1 \\
            0.5 & 1
        \end{array}\right]
        \left[ \begin{array}{c}
            x \\ y
        \end{array} \right] \leq
        \left[ \begin{array}{c}
            0.5 \\ 4.5
        \end{array} \right] 
    \right\}
\end{equation*}

The inverse of $\boldsymbol{\tilde A}$ is 
\begin{equation*}
    \boldsymbol{\tilde A}^{-1} =     
        \left[ \begin{array}{cc}
            -0.5 & 0.5 \\
            0.25 & 0.75
        \end{array}\right]
\end{equation*}
and we get the extreme rays $r_1 = (0.5 -2.5)$ and $r_2= (-0.5, -0.75)$.

After deriving the conic relaxation, we have $\bold{\tilde x} = \bold{\tilde A}^{-1} \bold{\tilde b}$ and $\bold r^j= - \boldsymbol{\tilde A}^{-1}_{*,j}$ \cite{bienstock_outer_product_free_sets}. For each extreme ray $\bold r^j$ there either exists an intersection with the boundary of $C$ in which case $\lambda^*_j > 0$ is the step length or the extreme ray is contained in $C$ and $\lambda^*_j= \infty$.
The \textit{intersection cut} is defined as \cite{bienstock_outer_product_free_sets}:
\begin{equation} \label{Eq:interscetion_cut}
    \sum_{i=1}^n (\bold{\tilde a}_{i,*} \bold x - \tilde b_i)/ \lambda_i^* \leq -1
\end{equation} 
% \unsure[inline]{do we need transpose here? \\MB: depends how you define your notation. It would make more sense to define the selected column as a column vector and use the transpose \\ matches outer-product-free set paper}
If we reformulate \cref{Eq:interscetion_cut}, we see that it matches the definition of a cut in \cref{Eq:cuts} \cite{bienstock_outer_product_free_sets}:
\begin{align}
    \sum_{i=1}^n (\bold{\tilde a}_{i,*} \bold x - \tilde b_i)/ \lambda_i^* &\leq -1 \\
    \sum_{i=1}^n ((1/ \lambda_i^*) \bold{\tilde a}_{i,*} \bold x - (1/ \lambda_i^*)\tilde b_i) &\leq -1 \\ 
    \sum_{i=1}^n (1/ \lambda_i^*) \bold{\tilde a}_{i,*} \bold x - \sum_{i=1}^n  (1/ \lambda_i^*)\tilde b_i &\leq -1 \\
    \sum_{i=1}^n (1/ \lambda_i^*) \bold{\tilde a}_{i,*} \bold x & \leq -1 + \sum_{i=1}^n  (1/ \lambda_i^*)\tilde b_i
\end{align}
\begin{equation*}
    \alpha_0 = -1 + \sum_{i=1}^n  (1/ \lambda_i^*)\tilde b_i \quad \quad \alpha_j = \sum_{i=1}^n (1/ \lambda_i^*) \bold{\tilde a}_{i,j} \bold x
\end{equation*}


\todo[inline]{explain why x is cut off}
\todo[inline]{update: basis defining x and basis for P}

% \unsure[inline]{does opt sense matter?\\MB: no it doesn't, intersection cuts don't cut off the objective}
% \todo[inline]{different cut formulations}
% \todo[inline]{use bar or tilde in intersection cuts? tilde already used for combinatorial benders}
